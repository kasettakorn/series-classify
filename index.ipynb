{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600601331936",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#Preprocessing video -> image frames\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "#Open the video file\n",
    "capture = cv2.VideoCapture('./datasets/คนละทีเดียวกัน.mp4')\n",
    "i = 0\n",
    "frameNumber = 1\n",
    "while(capture.isOpened()):\n",
    "    ret, frame = capture.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    if i % 3 == 0:\n",
    "        cv2.imwrite('./datasets/คนละทีเดียวกัน/คนละทีเดียวกัน'+str(frameNumber)+'.jpg', frame)\n",
    "        print('./datasets/คนละทีเดียวกัน/คนละทีเดียวกัน'+str(frameNumber)+'.jpg')\n",
    "        frameNumber = frameNumber+1\n",
    "    i = i+1\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#Resize image\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import imageio\n",
    "count = 1\n",
    "for path in sorted(os.listdir('./datasets/เพราะเรา(ยัง)คู่กัน')):\n",
    "    img = Image.open('./datasets/เพราะเรา(ยัง)คู่กัน/' + path)\n",
    "    img = img.resize((224,224), Image.NEAREST)\n",
    "    img = np.array(img)\n",
    "    imageio.imwrite('./datasets/2/' + str(count) + '.jpg', img)\n",
    "    print('./datasets/2/' + str(count) + '.jpg')\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "for path in os.listdir('./datasets/1/'):\n",
    "    img = Image.open('./datasets/1/'+path)\n",
    "    x_train.append(np.array(img))\n",
    "    y_train.append(1)\n",
    "    img.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "BATCH_SIZE_PER_REPLICA = 64\n",
    "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "step_size = 19647 // 64\n",
    "with strategy.scope():\n",
    "    base_model = ResNet50(include_top=False)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    prediction = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=prediction)\n",
    "    optimize = SGD(learning_rate=0.0001, momentum=0.9)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimize, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_train = x_train / 255.0\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.cache().shuffle(1000).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(train_data, epochs=10)\n",
    "model.save('weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import imutils\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "import imageio\n",
    "import copy\n",
    "from keras.models import load_model\n",
    "capture = cv2.VideoCapture('datasets/คนละทีเดียวกัน.mp4')\n",
    "success = 1\n",
    "\n",
    "model = load_model('weights.h5')\n",
    "while (True):\n",
    "  ret, frame = capture.read()\n",
    "  videoFrame = Image.fromarray(frame)\n",
    "  videoFrame = videoFrame.resize((800,400), Image.NEAREST)\n",
    "  videoFrame = np.array(videoFrame)\n",
    "  videoFrame = videoFrame.astype(np.float32)\n",
    "  videoFrame /= 255.0\n",
    "  \n",
    "  if (type(frame) != 'None'):\n",
    "    frame = Image.fromarray(frame)\n",
    "    frame = frame.resize((220,220), Image.NEAREST)\n",
    "    frame = np.array(frame)\n",
    "    frame = frame.astype(np.float32)\n",
    "    frame /= 255.0\n",
    "    pred_frame = np.expand_dims(frame, axis=0)\n",
    "    label = model.predict(pred_frame)\n",
    "    predict = \"\"\n",
    "    print(label[0], end=\"\")\n",
    "    if (label[0][0] > label[0][1]):\n",
    "        predict = \"I'm tee. Me too\"\n",
    "        print(\" -> คนละทีเดียวกัน\")\n",
    "    else:\n",
    "        predict = \"Still 2gether\"\n",
    "        print(\" -> เพราะเรา(ยัง)คู่กัน\")\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "\n",
    "    # inserting text on video \n",
    "    cv2.putText(videoFrame,  predict,  (50, 50),  font, 1,  (0, 255, 0), 2, cv2.LINE_4) \n",
    "    \n",
    "  \n",
    "    # Display the resulting frame \n",
    "    cv2.imshow('Series recognition', videoFrame) \n",
    "    \n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        capture.release() \n",
    "        cv2.destroyAllWindows() \n",
    "        break\n",
    "# release the cap object \n",
    "capture.release() \n",
    "# close all windows \n",
    "cv2.destroyAllWindows() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}